{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 畳み込みフィルターを用いた画像の分類"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import _pickle as pickle\n",
    "\n",
    "np.random.seed(42)\n",
    "tf.set_random_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('ORENIST.data', 'rb') as file:\n",
    "    images, labels = pickle.load(file, encoding='latin1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def edge_filter():\n",
    "    filter0 = np.array(\n",
    "        [[ 2, 1, 0, -1, -2],\n",
    "         [ 3, 2, 0, -2, -3],\n",
    "         [ 4, 3, 0, -2, -4],\n",
    "         [ 3, 2, 0, -2, -3],\n",
    "         [ 2, 1, 0, -1, -2]]) / 23.0 #ブロードキャストルールで全体を/23.0\n",
    "    \n",
    "    filter1 = np.array(\n",
    "        [[ 2, 3, 4, 3, 2],\n",
    "         [ 1, 2, 3, 2, 1],\n",
    "         [ 0, 0, 0, 0, 0],\n",
    "         [-1,-2,0,-2,-1],\n",
    "         [-2,-3,-4,-3,-2]]) / 23.0\n",
    "    \n",
    "    filter_array = np.zeros([5, 5, 1, 2])#フィルターの情報を格納しておく多次元リスト 5x5x1x2(フィルターサイズx入力レイヤー数x出力レイヤー数)\n",
    "    filter_array[:,:,0,0] = filter0 #一番目の出力レイヤーのフィルターサイズの部分に格納\n",
    "    filter_array[:,:,0,1] = filter1 #2番目の...\n",
    "        \n",
    "    return tf.constant(filter_array, dtype=tf.float32) # 用意した多次元リストをTensorFlowの定数値オブジェクトに変換したものを返している。\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.placeholder(tf.float32, [None, 784])\n",
    "x_image = tf.reshape(x, [-1, 28, 28, 1])\n",
    "\n",
    "W_conv = edge_filter()\n",
    "h_conv = tf.abs(tf.nn.conv2d(x_image, W_conv, strides = [1,1,1,1], padding='SAME'))\n",
    "\n",
    "h_conv_cutoff = tf.nn.relu(h_conv-0.2)\n",
    "\n",
    "h_pool = tf.nn.max_pool(h_conv_cutoff, ksize = [1,2,2,1], strides=[1,2,2,1], padding='SAME')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "h_pool_flat = tf.reshape(h_pool, [-1, 392]) #ベクトルに変換(一行の行列に変換)\n",
    "\n",
    "num_units1 = 392\n",
    "num_units2 = 2\n",
    "\n",
    "w2 = tf.Variable(tf.truncated_normal([num_units1, num_units2]))\n",
    "b2 = tf.Variable(tf.zeros([num_units2]))\n",
    "hidden2 = tf.nn.tanh(tf.matmul(h_pool_flat, w2) + b2)\n",
    "\n",
    "w0 = tf.Variable(tf.zeros([num_units2, 3]))\n",
    "b0 = tf.Variable(tf.zeros([3]))\n",
    "p = tf.nn.softmax(tf.matmul(hidden2, w0) +b0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = tf.placeholder(tf.float32, [None, 3])\n",
    "loss = - tf.reduce_sum(t * tf.log(p))\n",
    "train_step = tf.train.AdamOptimizer().minimize(loss)\n",
    "correct_prediction = tf.equal(tf.argmax(p, 1), tf.argmax(t, 1)) #tf.argmaxは第二引数に1を入れると行方向の一番大きい数字のindexを返す\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))# True or False を 1or0にキャスト"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.InteractiveSession()\n",
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracyが伸びない時はKernelをReconnectする\n",
    "原因はわからないがAccuracyが0.66つまり2/3の時は画像が1種欠けている"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 10, Loss: 98.171188, Accuracy: 0.688889\n",
      "Step: 20, Loss: 97.330765, Accuracy: 0.700000\n",
      "Step: 30, Loss: 96.323135, Accuracy: 0.733333\n",
      "Step: 40, Loss: 95.083107, Accuracy: 0.766667\n",
      "Step: 50, Loss: 93.566849, Accuracy: 0.788889\n",
      "Step: 60, Loss: 91.898178, Accuracy: 0.844444\n",
      "Step: 70, Loss: 90.155716, Accuracy: 0.866667\n",
      "Step: 80, Loss: 88.293488, Accuracy: 0.877778\n",
      "Step: 90, Loss: 86.287170, Accuracy: 0.922222\n",
      "Step: 100, Loss: 84.114830, Accuracy: 0.933333\n",
      "Step: 110, Loss: 81.871559, Accuracy: 0.955556\n",
      "Step: 120, Loss: 79.708672, Accuracy: 0.966667\n",
      "Step: 130, Loss: 77.654785, Accuracy: 0.977778\n",
      "Step: 140, Loss: 75.711777, Accuracy: 0.977778\n",
      "Step: 150, Loss: 73.904289, Accuracy: 0.988889\n",
      "Step: 160, Loss: 72.237602, Accuracy: 1.000000\n",
      "Step: 170, Loss: 70.686607, Accuracy: 1.000000\n",
      "Step: 180, Loss: 69.227425, Accuracy: 1.000000\n",
      "Step: 190, Loss: 67.841629, Accuracy: 1.000000\n",
      "Step: 200, Loss: 66.517006, Accuracy: 1.000000\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "for _ in range(200):\n",
    "    i += 1\n",
    "    sess.run(train_step, feed_dict = {x:images, t:labels})\n",
    "    if i % 10 ==0:\n",
    "        loss_val, acc_val = sess.run([loss, accuracy], feed_dict = {x:images, t:labels})\n",
    "        print('Step: %d, Loss: %f, Accuracy: %f' % (i, loss_val, acc_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "z1,z2座標を見ると分類できていることがわかる。あとは平面上の分類と同じ作業"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "hidden2_vals = sess.run(hidden2, feed_dict={x:images})\n",
    "\n",
    "z1_vals = [[], [], []]\n",
    "z2_vals = [[], [], []]\n",
    "\n",
    "for hidden2_val, label in zip(hidden2_vals, labels):\n",
    "    label_num = np.argmax(label)\n",
    "    z1_vals[label_num].append(hidden2_val[0])\n",
    "    z2_vals[label_num].append(hidden2_val[1])\n",
    "    \n",
    "fig = plt.figure(figsize=(5,5))\n",
    "subplot = fig.add_subplot(1,1,1)\n",
    "subplot.scatter(z1_vals[0], z2_vals[0], s = 200, marker = '|')\n",
    "subplot.scatter(z1_vals[1], z2_vals[1], s = 200, marker = '_')\n",
    "subplot.scatter(z1_vals[2], z2_vals[2], s = 200, marker = '+')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
